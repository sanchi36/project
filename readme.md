Up to 15 million Americans have food allergies, with the number going up each year.  Americans spent about $46 billion each year in 2004 alone for weight-loss products. Given such growing numbers, it is obvious Americans are coming to place a strong emphasis on not only what they choose to consume, but also going healthy. However, given the consumer-driven economy of the United States and a vast majority of people have minimal dietary preferences and/or restrictions, it is reasonable to note that when it comes to food, it is challenging for a typical individual to find the right food to match their diet.

Our proposed solution hopes to aid people in learning a little more about their food before they choose to consume it.This application aims to identify a picture of a food item from a predefined set of foods, and also to recognize the possible ingredients and estimate the approximate number of calories.

Food Images were trained on a Deep Neural Network consisting of 8 layers, from which the first 5 layers are Convolutional Neural Networks used from Alexnet and the last 3 layers are fully connected layers designed by us. Softmax is used in the last layer to classify the images and dropout was used to avoid overfitting. Sigmoid activation function was used in this model.
